{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SabnamNayak/DS_Assignments/blob/main/Logistic_Reg_churn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGv6CY6S8wZk"
      },
      "source": [
        "### Customer churn with Logistic Regression\n",
        "A telecommunications company is concerned about the number of customers leaving their land-line business for cable competitors. They need to understand who is leaving. Imagine that you are an analyst at this company and you have to find out who is leaving and why."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "P8oFPuba8wZl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import pylab as pl\n",
        "import numpy as np\n",
        "import scipy.optimize as opt\n",
        "from sklearn import preprocessing\n",
        "%matplotlib inline \n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "gBv_klqf8wZm"
      },
      "source": [
        "### Load Data From CSV File  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "fD5ODEly8wZm",
        "outputId": "a5c1271c-03c2-4e26-c5c5-c71723b73c45"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tenure</th>\n",
              "      <th>age</th>\n",
              "      <th>address</th>\n",
              "      <th>income</th>\n",
              "      <th>ed</th>\n",
              "      <th>employ</th>\n",
              "      <th>equip</th>\n",
              "      <th>callcard</th>\n",
              "      <th>wireless</th>\n",
              "      <th>longmon</th>\n",
              "      <th>...</th>\n",
              "      <th>pager</th>\n",
              "      <th>internet</th>\n",
              "      <th>callwait</th>\n",
              "      <th>confer</th>\n",
              "      <th>ebill</th>\n",
              "      <th>loglong</th>\n",
              "      <th>logtoll</th>\n",
              "      <th>lninc</th>\n",
              "      <th>custcat</th>\n",
              "      <th>churn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>136.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.40</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.482</td>\n",
              "      <td>3.033</td>\n",
              "      <td>4.913</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>33.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.45</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.246</td>\n",
              "      <td>3.240</td>\n",
              "      <td>3.497</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>23.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.30</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.841</td>\n",
              "      <td>3.240</td>\n",
              "      <td>3.401</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>38.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.05</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.800</td>\n",
              "      <td>3.807</td>\n",
              "      <td>4.331</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.10</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.960</td>\n",
              "      <td>3.091</td>\n",
              "      <td>4.382</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 28 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   tenure   age  address  income   ed  employ  equip  callcard  wireless  \\\n",
              "0    11.0  33.0      7.0   136.0  5.0     5.0    0.0       1.0       1.0   \n",
              "1    33.0  33.0     12.0    33.0  2.0     0.0    0.0       0.0       0.0   \n",
              "2    23.0  30.0      9.0    30.0  1.0     2.0    0.0       0.0       0.0   \n",
              "3    38.0  35.0      5.0    76.0  2.0    10.0    1.0       1.0       1.0   \n",
              "4     7.0  35.0     14.0    80.0  2.0    15.0    0.0       1.0       0.0   \n",
              "\n",
              "   longmon  ...  pager  internet  callwait  confer  ebill  loglong  logtoll  \\\n",
              "0     4.40  ...    1.0       0.0       1.0     1.0    0.0    1.482    3.033   \n",
              "1     9.45  ...    0.0       0.0       0.0     0.0    0.0    2.246    3.240   \n",
              "2     6.30  ...    0.0       0.0       0.0     1.0    0.0    1.841    3.240   \n",
              "3     6.05  ...    1.0       1.0       1.0     1.0    1.0    1.800    3.807   \n",
              "4     7.10  ...    0.0       0.0       1.0     1.0    0.0    1.960    3.091   \n",
              "\n",
              "   lninc  custcat  churn  \n",
              "0  4.913      4.0    1.0  \n",
              "1  3.497      1.0    1.0  \n",
              "2  3.401      3.0    0.0  \n",
              "3  4.331      4.0    0.0  \n",
              "4  4.382      3.0    0.0  \n",
              "\n",
              "[5 rows x 28 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "churn_df = pd.read_csv(\"D:\\My Documents\\Machine Learning\\DataSets/ChurnData.csv\")\n",
        "churn_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_xwZECQ8wZn"
      },
      "source": [
        "<h2 id=\"preprocessing\">Data pre-processing and selection</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nd1B05IU8wZo"
      },
      "source": [
        "Lets select some features for the modeling. Also we change the target data type to be integer, as it is a requirement  by the skitlearn algorithm:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0yBNnxA8wZo",
        "outputId": "cdfb7301-f53f-4521-bec2-b81667d67f3b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tenure</th>\n",
              "      <th>age</th>\n",
              "      <th>address</th>\n",
              "      <th>income</th>\n",
              "      <th>ed</th>\n",
              "      <th>employ</th>\n",
              "      <th>equip</th>\n",
              "      <th>callcard</th>\n",
              "      <th>wireless</th>\n",
              "      <th>churn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>136.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>33.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>23.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>38.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   tenure   age  address  income   ed  employ  equip  callcard  wireless  \\\n",
              "0    11.0  33.0      7.0   136.0  5.0     5.0    0.0       1.0       1.0   \n",
              "1    33.0  33.0     12.0    33.0  2.0     0.0    0.0       0.0       0.0   \n",
              "2    23.0  30.0      9.0    30.0  1.0     2.0    0.0       0.0       0.0   \n",
              "3    38.0  35.0      5.0    76.0  2.0    10.0    1.0       1.0       1.0   \n",
              "4     7.0  35.0     14.0    80.0  2.0    15.0    0.0       1.0       0.0   \n",
              "\n",
              "   churn  \n",
              "0      1  \n",
              "1      1  \n",
              "2      0  \n",
              "3      0  \n",
              "4      0  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "churn_df = churn_df[['tenure', 'age', 'address', 'income', 'ed', 'employ', 'equip',   'callcard', 'wireless','churn']]\n",
        "churn_df['churn'] = churn_df['churn'].astype('int')\n",
        "churn_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": true,
        "new_sheet": true,
        "run_control": {
          "read_only": false
        },
        "id": "Qs-RZ5MY8wZp"
      },
      "source": [
        "## Practice\n",
        "How many rows and columns are in this dataset in total? What are the name of columns?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "bogeucaR8wZp",
        "outputId": "685d9b13-4c74-435d-b039-4312463b58c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['tenure', 'age', 'address', 'income', 'ed', 'employ', 'equip',\n",
              "       'callcard', 'wireless', 'churn'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# write your code here\n",
        "churn_df.shape\n",
        "churn_df.columns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rC1ZQKD18wZp"
      },
      "source": [
        "Lets define X, and y for our dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4eeeCXyU8wZq",
        "outputId": "4463987e-0918-4912-ab04-8af27cbed91d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 11.,  33.,   7., 136.,   5.,   5.,   0.],\n",
              "       [ 33.,  33.,  12.,  33.,   2.,   0.,   0.],\n",
              "       [ 23.,  30.,   9.,  30.,   1.,   2.,   0.],\n",
              "       [ 38.,  35.,   5.,  76.,   2.,  10.,   1.],\n",
              "       [  7.,  35.,  14.,  80.,   2.,  15.,   0.]])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = np.asarray(churn_df[['tenure', 'age', 'address', 'income', 'ed', 'employ', 'equip']])\n",
        "X[0:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUOneYLa8wZq",
        "outputId": "00c41e8c-fe62-4064-e545-2be8c8eae64f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 1, 0, 0, 0])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = np.asarray(churn_df['churn'])\n",
        "y [0:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOqInLi98wZq"
      },
      "source": [
        "Also, we normalize the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wTVyZaF8wZq",
        "outputId": "f6c66641-2dbb-42fc-c571-974702ce4220"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-1.13518441, -0.62595491, -0.4588971 ,  0.4751423 ,  1.6961288 ,\n",
              "        -0.58477841, -0.85972695],\n",
              "       [-0.11604313, -0.62595491,  0.03454064, -0.32886061, -0.6433592 ,\n",
              "        -1.14437497, -0.85972695],\n",
              "       [-0.57928917, -0.85594447, -0.261522  , -0.35227817, -1.42318853,\n",
              "        -0.92053635, -0.85972695],\n",
              "       [ 0.11557989, -0.47262854, -0.65627219,  0.00679109, -0.6433592 ,\n",
              "        -0.02518185,  1.16316   ],\n",
              "       [-1.32048283, -0.47262854,  0.23191574,  0.03801451, -0.6433592 ,\n",
              "         0.53441472, -0.85972695]])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn import preprocessing\n",
        "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
        "X[0:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMw-7kwg8wZq"
      },
      "source": [
        "## Train/Test dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXHEMKFD8wZq"
      },
      "source": [
        "Okay, we split our dataset into train and test set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0D3jQljI8wZr",
        "outputId": "9539f15f-4d61-4b9c-ae7f-ed9898c1a35c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train set: (160, 7) (160,)\n",
            "Test set: (40, 7) (40,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)\n",
        "print ('Train set:', X_train.shape,  y_train.shape)\n",
        "print ('Test set:', X_test.shape,  y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugfqltUa8wZr"
      },
      "source": [
        "<h2 id=\"modeling\">Modeling (Logistic Regression with Scikit-learn)</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3Jn1rOV8wZr",
        "outputId": "115ba4e2-f25b-41f7-e97d-d06e976dc56b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
              "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
              "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
              "          tol=0.0001, verbose=0, warm_start=False)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "LR = LogisticRegression(C=0.01, solver='liblinear').fit(X_train,y_train)\n",
        "LR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5zymNW4V8wZs",
        "outputId": "d8f1c3db-61fe-43ec-e2d0-03ade5124c81"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "yhat = LR.predict(X_test)\n",
        "yhat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vV06Omat8wZs",
        "outputId": "2f1ad1eb-27a1-4d77-a32f-255cfb15a9be"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.54132919, 0.45867081],\n",
              "       [0.60593357, 0.39406643],\n",
              "       [0.56277713, 0.43722287],\n",
              "       [0.63432489, 0.36567511],\n",
              "       [0.56431839, 0.43568161],\n",
              "       [0.55386646, 0.44613354],\n",
              "       [0.52237207, 0.47762793],\n",
              "       [0.60514349, 0.39485651],\n",
              "       [0.41069572, 0.58930428],\n",
              "       [0.6333873 , 0.3666127 ],\n",
              "       [0.58068791, 0.41931209],\n",
              "       [0.62768628, 0.37231372],\n",
              "       [0.47559883, 0.52440117],\n",
              "       [0.4267593 , 0.5732407 ],\n",
              "       [0.66172417, 0.33827583],\n",
              "       [0.55092315, 0.44907685],\n",
              "       [0.51749946, 0.48250054],\n",
              "       [0.485743  , 0.514257  ],\n",
              "       [0.49011451, 0.50988549],\n",
              "       [0.52423349, 0.47576651],\n",
              "       [0.61619519, 0.38380481],\n",
              "       [0.52696302, 0.47303698],\n",
              "       [0.63957168, 0.36042832],\n",
              "       [0.52205164, 0.47794836],\n",
              "       [0.50572852, 0.49427148],\n",
              "       [0.70706202, 0.29293798],\n",
              "       [0.55266286, 0.44733714],\n",
              "       [0.52271594, 0.47728406],\n",
              "       [0.51638863, 0.48361137],\n",
              "       [0.71331391, 0.28668609],\n",
              "       [0.67862111, 0.32137889],\n",
              "       [0.50896403, 0.49103597],\n",
              "       [0.42348082, 0.57651918],\n",
              "       [0.71495838, 0.28504162],\n",
              "       [0.59711064, 0.40288936],\n",
              "       [0.63808839, 0.36191161],\n",
              "       [0.39957895, 0.60042105],\n",
              "       [0.52127638, 0.47872362],\n",
              "       [0.65975464, 0.34024536],\n",
              "       [0.5114172 , 0.4885828 ]])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "yhat_prob = LR.predict_proba(X_test)\n",
        "yhat_prob"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ek7RtAPo8wZs"
      },
      "source": [
        "<h2 id=\"evaluation\">Evaluation</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mp6e6vsq8wZs"
      },
      "source": [
        "### jaccard index\n",
        "Lets try jaccard index for accuracy evaluation. we can define jaccard as the size of the intersection divided by the size of the union of two label sets. If the entire set of predicted labels for a sample strictly match with the true set of labels, then the subset accuracy is 1.0; otherwise it is 0.0.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWzzt1C-8wZs",
        "outputId": "e5770860-d6c5-41b7-ef1d-381c6bbd5350"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.75"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import jaccard_similarity_score\n",
        "jaccard_similarity_score(y_test, yhat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1UxURru8wZt",
        "outputId": "fefbc8ae-c7cc-4099-f61a-6d239b921f6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.96      0.83        25\n",
            "           1       0.86      0.40      0.55        15\n",
            "\n",
            "   micro avg       0.75      0.75      0.75        40\n",
            "   macro avg       0.79      0.68      0.69        40\n",
            "weighted avg       0.78      0.75      0.72        40\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print (classification_report(y_test, yhat))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-3UPZGs8wZt"
      },
      "source": [
        "### log loss\n",
        "Now, lets try __log loss__ for evaluation. In logistic regression, the output can be the probability of customer churn is yes (or equals to 1). This probability is a value between 0 and 1.\n",
        "Log loss( Logarithmic loss) measures the performance of a classifier where the predicted output is a probability value between 0 and 1. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oAkqNfQG8wZt",
        "outputId": "381eee29-a730-4c18-c698-6c92271239e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6017092478101185"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import log_loss\n",
        "log_loss(y_test, yhat_prob)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}